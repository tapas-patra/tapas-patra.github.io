// lib/mistral.js
const CONFIG = require('./config');

// Rate limiting management
const rateLimitManager = {
  lastRequestTime: 0,
  minRequestInterval: CONFIG.RATE_LIMIT.MIN_INTERVAL,
  retryCount: 0,
  maxRetries: CONFIG.RATE_LIMIT.MAX_RETRIES,
  isWaitingForRateLimit: false,

  // Get delay time for exponential backoff
  getRetryDelay() {
    // Exponential backoff with jitter: 2^retryCount * baseDelay + random jitter
    return Math.min(
      (Math.pow(2, this.retryCount) * CONFIG.RATE_LIMIT.BASE_DELAY) + (Math.random() * 1000),
      CONFIG.RATE_LIMIT.MAX_DELAY
    );
  },

  // Reset retry count
  reset() {
    this.retryCount = 0;
    this.isWaitingForRateLimit = false;
  },

  // Increment retry count
  incrementRetry() {
    this.retryCount++;
    return this.retryCount <= this.maxRetries;
  },

  // Ensure we're not sending requests too quickly
  async enforceRateLimit() {
    const now = Date.now();
    const timeSinceLastRequest = now - this.lastRequestTime;

    if (timeSinceLastRequest < this.minRequestInterval) {
      // Wait before proceeding
      const waitTime = this.minRequestInterval - timeSinceLastRequest;
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }

    this.lastRequestTime = Date.now();
  }
};

// Generate embeddings with rate limit handling
async function createEmbedding(text) {
  // Reset retry counter at the start of a new request
  rateLimitManager.reset();

  // Keep trying until we hit max retries
  while (true) {
    try {
      // Enforce rate limiting
      await rateLimitManager.enforceRateLimit();

      const response = await fetch('https://api.mistral.ai/v1/embeddings', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${CONFIG.MISTRAL_API_KEY}`
        },
        body: JSON.stringify({
          model: CONFIG.MISTRAL_EMBEDDING_MODEL,
          input: text
        })
      });

      if (response.status === 429) {
        // Handle rate limit
        const retryAfter = response.headers.get('Retry-After') ||
                           rateLimitManager.getRetryDelay() / 1000;

        console.warn(`Rate limited. Retrying after ${retryAfter} seconds.`);

        // Check if we should retry
        if (!rateLimitManager.incrementRetry()) {
          throw new Error('Maximum retry attempts reached for rate limiting');
        }

        // Wait before retrying
        const delayMs = retryAfter * 1000 || rateLimitManager.getRetryDelay();
        rateLimitManager.isWaitingForRateLimit = true;

        await new Promise(resolve => setTimeout(resolve, delayMs));
        rateLimitManager.isWaitingForRateLimit = false;

        // Try again
        continue;
      }

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`Mistral API Error: ${errorData.error?.message || response.statusText}`);
      }

      const data = await response.json();
      return data.data[0].embedding;

    } catch (error) {
      // If it's not a rate limit error or we've exceeded retries, throw
      if (!rateLimitManager.isWaitingForRateLimit || rateLimitManager.retryCount > rateLimitManager.maxRetries) {
        console.error('Error generating embedding:', error);
        throw error;
      }
      // Otherwise, the loop will continue
    }
  }
}

// Generate chat completion with rate limit handling
async function generateChatCompletion(messages) {
  // Reset retry counter at the start of a new request
  rateLimitManager.reset();

  // Keep trying until we hit max retries
  while (true) {
    try {
      // Enforce rate limiting
      await rateLimitManager.enforceRateLimit();

      const response = await fetch('https://api.mistral.ai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${CONFIG.MISTRAL_API_KEY}`
        },
        body: JSON.stringify({
          model: CONFIG.MISTRAL_COMPLETION_MODEL,
          messages: messages
        })
      });

      if (response.status === 429) {
        // Handle rate limit
        const retryAfter = response.headers.get('Retry-After') ||
                           rateLimitManager.getRetryDelay() / 1000;

        console.warn(`Rate limited. Retrying after ${retryAfter} seconds.`);

        // Check if we should retry
        if (!rateLimitManager.incrementRetry()) {
          throw new Error('Maximum retry attempts reached for rate limiting');
        }

        // Wait before retrying
        const delayMs = retryAfter * 1000 || rateLimitManager.getRetryDelay();
        rateLimitManager.isWaitingForRateLimit = true;

        await new Promise(resolve => setTimeout(resolve, delayMs));
        rateLimitManager.isWaitingForRateLimit = false;

        // Try again
        continue;
      }

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`Mistral API Error: ${errorData.error?.message || response.statusText}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;

    } catch (error) {
      // If it's not a rate limit error or we've exceeded retries, throw
      if (!rateLimitManager.isWaitingForRateLimit || rateLimitManager.retryCount > rateLimitManager.maxRetries) {
        console.error('Error generating chat completion:', error);
        throw error;
      }
      // Otherwise, the loop will continue
    }
  }
}

module.exports = {
  createEmbedding,
  generateChatCompletion
};
